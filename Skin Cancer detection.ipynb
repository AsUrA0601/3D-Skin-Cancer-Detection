{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763adceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T00:00:34.202131Z",
     "iopub.status.busy": "2025-04-01T00:00:34.201748Z",
     "iopub.status.idle": "2025-04-01T00:00:48.268763Z",
     "shell.execute_reply": "2025-04-01T00:00:48.267991Z"
    },
    "papermill": {
     "duration": 14.072951,
     "end_time": "2025-04-01T00:00:48.270398",
     "exception": false,
     "start_time": "2025-04-01T00:00:34.197447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 1: Environment Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2B0, ResNet50\n",
    "from tensorflow.keras import layers, models, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.ndimage import zoom\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa99e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T00:00:48.277676Z",
     "iopub.status.busy": "2025-04-01T00:00:48.277149Z",
     "iopub.status.idle": "2025-04-01T00:02:37.345608Z",
     "shell.execute_reply": "2025-04-01T00:02:37.344740Z"
    },
    "papermill": {
     "duration": 109.075817,
     "end_time": "2025-04-01T00:02:37.349401",
     "exception": false,
     "start_time": "2025-04-01T00:00:48.273584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 2: Optimized Data Loading & Augmentation for Malignant Cases\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "\n",
    "# Set paths\n",
    "TRAIN_IMAGE_DIR = '/kaggle/input/isic-2024-challenge/train-image/image/'\n",
    "AUG_IMAGE_DIR = '/kaggle/working/augmented-images/' \n",
    "\n",
    "# Create directory if not exists\n",
    "os.makedirs(AUG_IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "# Augmentation settings\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  \n",
    "    zoom_range=0.1,  \n",
    "    horizontal_flip=True,  \n",
    "    brightness_range=[0.8, 1.2],  \n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def augment_malignant_images(malignant_df, target_count=20000):\n",
    "    \"\"\"Generates synthetic malignant images to balance dataset.\"\"\"\n",
    "    new_malignant_paths = []\n",
    "    total_needed = target_count - len(malignant_df)\n",
    "    augment_per_image = total_needed // len(malignant_df)  # ~50x per image\n",
    "    \n",
    "    print(f\"Generating {total_needed} new malignant images...\")\n",
    "    \n",
    "    for _, row in malignant_df.iterrows():\n",
    "        img_path = row['image_path']\n",
    "        img = load_img(img_path)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "        \n",
    "        # Generate augmented images\n",
    "        for i in range(augment_per_image):\n",
    "            aug_img = datagen.flow(img_array, batch_size=1)[0][0]\n",
    "            aug_img = array_to_img(aug_img)\n",
    "            \n",
    "            # Save new image\n",
    "            new_img_path = os.path.join(AUG_IMAGE_DIR, f\"aug_{row['isic_id']}_{i}.jpg\")\n",
    "            aug_img.save(new_img_path)\n",
    "            new_malignant_paths.append({'isic_id': f\"aug_{row['isic_id']}_{i}\", 'target': 1, 'image_path': new_img_path})\n",
    "    \n",
    "    print(f\"Augmentation complete! {len(new_malignant_paths)} new malignant images created.\")\n",
    "    return pd.DataFrame(new_malignant_paths)\n",
    "\n",
    "def load_balanced_data():\n",
    "    start = time.time()\n",
    "    \n",
    "    # 1. Load Metadata\n",
    "    print(\"Loading metadata...\")\n",
    "    train_meta = pd.read_csv(\n",
    "        '/kaggle/input/isic-2024-challenge/train-metadata.csv',\n",
    "        usecols=['isic_id', 'target'],\n",
    "        dtype={'isic_id': 'string', 'target': 'int8'},\n",
    "        low_memory=False\n",
    "    )\n",
    "    \n",
    "    # 2. Build Image Paths\n",
    "    print(\"Building paths...\")\n",
    "    train_meta['image_path'] = TRAIN_IMAGE_DIR + train_meta['isic_id'] + '.jpg'\n",
    "    \n",
    "    # 3. Filter Existing Images\n",
    "    print(\"Verifying files...\")\n",
    "    existing_files = set(os.listdir(TRAIN_IMAGE_DIR))\n",
    "    mask = (train_meta['isic_id'] + '.jpg').isin(existing_files)\n",
    "    train_df = train_meta[mask].copy()\n",
    "    \n",
    "    # 4. Split Malignant and Benign\n",
    "    print(\"Balancing classes...\")\n",
    "    malignant_df = train_df[train_df['target'] == 1].copy()\n",
    "    benign_df = train_df[train_df['target'] == 0].copy()\n",
    "    \n",
    "    # 5. Augment Malignant Images\n",
    "    aug_malignant_df = augment_malignant_images(malignant_df, target_count=20000)\n",
    "    \n",
    "    # 6. Sample 20,000 Benign Images\n",
    "    benign_sampled = benign_df.sample(n=20000, random_state=42)\n",
    "    \n",
    "    # 7. Merge Augmented Malignant + Benign\n",
    "    final_df = pd.concat([aug_malignant_df, benign_sampled], ignore_index=True)\n",
    "    \n",
    "    # 8. Shuffle Data\n",
    "    final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Data loaded & augmented in {time.time()-start:.2f}s\")\n",
    "    return final_df\n",
    "\n",
    "# Run data loading & augmentation\n",
    "train_df = load_balanced_data()\n",
    "\n",
    "print(\"\\nFinal class distribution:\")\n",
    "print(train_df['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be9454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T00:02:37.356246Z",
     "iopub.status.busy": "2025-04-01T00:02:37.355995Z",
     "iopub.status.idle": "2025-04-01T00:02:37.379031Z",
     "shell.execute_reply": "2025-04-01T00:02:37.377721Z"
    },
    "papermill": {
     "duration": 0.028574,
     "end_time": "2025-04-01T00:02:37.381066",
     "exception": false,
     "start_time": "2025-04-01T00:02:37.352492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: Data Preprocessing & Splitting\n",
    "# Split data\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    stratify=train_df['target'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(path, img_size=(256, 256)):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, img_size)\n",
    "    return img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1259e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T00:02:37.389126Z",
     "iopub.status.busy": "2025-04-01T00:02:37.388698Z",
     "iopub.status.idle": "2025-04-01T00:02:37.394935Z",
     "shell.execute_reply": "2025-04-01T00:02:37.394058Z"
    },
    "papermill": {
     "duration": 0.012349,
     "end_time": "2025-04-01T00:02:37.397169",
     "exception": false,
     "start_time": "2025-04-01T00:02:37.384820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: 2D Ensemble Model\n",
    "def build_2d_ensemble():\n",
    "    input_layer = layers.Input(shape=(256, 256, 3))\n",
    "    \n",
    "    # Feature Extraction\n",
    "    effnet = EfficientNetV2B0(include_top=False, weights='imagenet')(input_layer)\n",
    "    resnet = ResNet50(include_top=False, weights='imagenet')(input_layer)\n",
    "    \n",
    "    # Feature Processing\n",
    "    x1 = layers.GlobalAveragePooling2D()(effnet)\n",
    "    x2 = layers.GlobalAveragePooling2D()(resnet)\n",
    "    merged = layers.concatenate([x1, x2])\n",
    "    \n",
    "    # Classifier\n",
    "    x = layers.Dense(512, activation='relu')(merged)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713fde1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T00:02:37.405488Z",
     "iopub.status.busy": "2025-04-01T00:02:37.405152Z",
     "iopub.status.idle": "2025-04-01T01:18:13.715648Z",
     "shell.execute_reply": "2025-04-01T01:18:13.714702Z"
    },
    "papermill": {
     "duration": 4536.316003,
     "end_time": "2025-04-01T01:18:13.717140",
     "exception": false,
     "start_time": "2025-04-01T00:02:37.401137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 5: 2D Model Training\n",
    "# Data generators\n",
    "train_gen = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_data['image_path'].values, train_data['target'].values)\n",
    ").map(lambda x,y: (preprocess_image(x), y)).batch(32)\n",
    "\n",
    "val_gen = tf.data.Dataset.from_tensor_slices(\n",
    "    (val_data['image_path'].values, val_data['target'].values)\n",
    ").map(lambda x,y: (preprocess_image(x), y)).batch(32)\n",
    "\n",
    "# Train and save\n",
    "model_2d = build_2d_ensemble()\n",
    "history_2d = model_2d.fit(train_gen, validation_data=val_gen, epochs=15)\n",
    "model_2d.save('/kaggle/working/2d_model.h5')\n",
    "\n",
    "# After saving 2D model\n",
    "print(\"Files in working directory:\")\n",
    "print(os.listdir('/kaggle/working/'))\n",
    "\n",
    "# Verify model file exists\n",
    "if os.path.exists('/kaggle/working/2d_model.h5'):\n",
    "    print(\"\\n2D model saved successfully!\")\n",
    "    print(f\"File size: {os.path.getsize('/kaggle/working/2d_model.h5')/1e6:.1f} MB\")\n",
    "else:\n",
    "    print(\"\\nError: 2D model not saved!\")\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history_2d.history['accuracy'], label='Train')\n",
    "plt.plot(history_2d.history['val_accuracy'], label='Validation')\n",
    "plt.title('2D Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history_2d.history['auc'], label='Train')\n",
    "plt.plot(history_2d.history['val_auc'], label='Validation')\n",
    "plt.title('2D Model AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d018aa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T01:18:15.285940Z",
     "iopub.status.busy": "2025-04-01T01:18:15.285415Z"
    },
    "papermill": {
     "duration": 1157.531554,
     "end_time": "2025-04-01T01:37:32.073057",
     "exception": false,
     "start_time": "2025-04-01T01:18:14.541503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6: Monodepth 3D Augmentation with Visualization\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "class VolumetricConverter:\n",
    "    def __init__(self, depth=16, img_size=(256, 256)):\n",
    "        self.depth = depth\n",
    "        self.img_size = img_size\n",
    "        self.aug = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='constant'\n",
    "        )\n",
    "\n",
    "    def convert_to_3d(self, img_array):\n",
    "        \"\"\"Convert a 2D image into a 3D volumetric structure\"\"\"\n",
    "        slices = []\n",
    "        base_img = img_array.numpy() if tf.is_tensor(img_array) else img_array\n",
    "        for i in range(self.depth):\n",
    "            augmented = self.aug.random_transform(base_img)\n",
    "            slices.append(augmented[:, :, 0])  # Use grayscale intensity for volume\n",
    "\n",
    "        volume = np.stack(slices, axis=2)  # Shape: (256, 256, depth)\n",
    "        return volume\n",
    "\n",
    "def visualize_3d_and_2d(volume_3d, original_2d):\n",
    "    \"\"\"Render 3D volumetric structure and its 2D counterpart\"\"\"\n",
    "    fig = plt.figure(figsize=(10, 12))\n",
    "\n",
    "    # 3D Volumetric Rendering\n",
    "    ax1 = fig.add_subplot(2, 1, 1, projection='3d')\n",
    "    verts, faces, _, _ = marching_cubes(volume_3d, level=np.mean(volume_3d))\n",
    "    ax1.plot_trisurf(verts[:, 0], verts[:, 1], faces, verts[:, 2], cmap='coolwarm', alpha=0.7)\n",
    "    ax1.set_title(\"3D Volumetric Representation\")\n",
    "\n",
    "    # 2D Image Display\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "    ax2.imshow(original_2d, cmap='gray')\n",
    "    ax2.set_title(\"Original 2D Image\")\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Initialize converter\n",
    "converter = VolumetricConverter(depth=16)\n",
    "\n",
    "# Convert entire dataset to 3D\n",
    "df_3d = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    img_path = row['image_path']\n",
    "    original_img = preprocess_image(img_path)  # Load and preprocess 2D image\n",
    "    volume_3d = converter.convert_to_3d(original_img)  # Convert to 3D\n",
    "    df_3d.append({'image_path': img_path, 'volume_3d': volume_3d})  # Store 3D version\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_3d = pd.DataFrame(df_3d)\n",
    "\n",
    "# Select a random image from df_3d for visualization\n",
    "sample_idx = np.random.choice(len(df_3d))\n",
    "sample_data = df_3d.iloc[sample_idx]\n",
    "sample_3d = sample_data['volume_3d']\n",
    "sample_2d = preprocess_image(sample_data['image_path'])\n",
    "\n",
    "# Visualize both 3D and 2D versions\n",
    "visualize_3d_and_2d(sample_3d, sample_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9defea9c",
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-31T23:59:18.247Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 7: 3D CNN Training & Evaluation\n",
    "# 1. Prepare 3D dataset\n",
    "# Convert DataFrame to numpy arrays\n",
    "X = np.array(df_3d['volume_3d'].tolist())[..., np.newaxis] \n",
    "y = train_df['target'].values\n",
    "\n",
    "# Verify input shape\n",
    "print(f\"Input shape: {X.shape}\") \n",
    "\n",
    "# 2. Split into train/validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. Build 3D CNN model\n",
    "def build_3d_cnn(input_shape=(256, 256, 16, 1)):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        # Feature extraction\n",
    "        layers.Conv3D(32, (3, 3, 3), activation='relu'),\n",
    "        layers.MaxPooling3D((2, 2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Conv3D(64, (3, 3, 3), activation='relu'),\n",
    "        layers.MaxPooling3D((2, 2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Classification\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 4. Train the model\n",
    "model_3d = build_3d_cnn()\n",
    "model_3d.summary()\n",
    "\n",
    "history = model_3d.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=15,\n",
    "    batch_size=8,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5. Save the model\n",
    "model_3d.save('/kaggle/working/3d_cnn_model.h5')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# 6. Visualize training history\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e75036",
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-31T23:59:18.247Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for model files\n",
    "print(\"Files in working directory:\")\n",
    "print(os.listdir('/kaggle/working/'))\n",
    "\n",
    "# Verify specific models\n",
    "print(\"\\n2D model exists:\", os.path.exists('/kaggle/working/2d_model.h5'))\n",
    "print(\"3D model exists:\", os.path.exists('/kaggle/working/3d_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af2d49",
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-31T23:59:18.247Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 8: Prediction Pipeline\n",
    "# 1. Load models\n",
    "model_2d = tf.keras.models.load_model('/kaggle/working/2d_model.h5')\n",
    "model_3d = tf.keras.models.load_model('/kaggle/working/3d_model.h5')\n",
    "\n",
    "# 2. Preprocess test image\n",
    "def preprocess_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (256, 256))\n",
    "    return img / 255.0\n",
    "\n",
    "test_image = preprocess_image('/kaggle/input/skin-cancer-test/basal-cell-carcinoma-stock.jpg')\n",
    "\n",
    "# 3. 2D Prediction\n",
    "planar_pred = model_2d.predict(np.expand_dims(test_image, 0))[0][0]\n",
    "\n",
    "# 4. 3D Conversion (Fixed)\n",
    "class VolumetricConverter:\n",
    "    def __init__(self, depth=16):\n",
    "        self.depth = 16\n",
    "        self.aug = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "    \n",
    "    def convert_to_3d(self, img_array):\n",
    "        \"\"\"Convert to (256, 256, 16, 1) grayscale volume\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray_img = tf.image.rgb_to_grayscale(img_array)\n",
    "        slices = []\n",
    "        for _ in range(self.depth):\n",
    "            augmented = self.aug.random_transform(gray_img.numpy())\n",
    "            slices.append(augmented[..., 0])  # Remove channel dim\n",
    "        return np.stack(slices, axis=2)[..., np.newaxis]  # Add single channel\n",
    "\n",
    "converter = VolumetricConverter()\n",
    "test_volume = converter.convert_to_3d(test_image)\n",
    "test_volume = np.expand_dims(test_volume, axis=0)  # Add batch dimension\n",
    "\n",
    "# 5. 3D Prediction\n",
    "depth_pred = model_3d.predict(test_volume)[0][0]\n",
    "\n",
    "# 6. Format and display results\n",
    "def format_pred(pred):\n",
    "    return f\"Malignant: {pred*100:.1f}%\\nBenign: {(1-pred)*100:.1f}%\"\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image)\n",
    "plt.title(\"Test Image\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.text(0.1, 0.7, \"Planar Analysis (2D):\\n\" + format_pred(planar_pred), \n",
    "         fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.text(0.1, 0.4, \"Depth Analysis (3D):\\n\" + format_pred(depth_pred),\n",
    "         fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c104f",
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-31T23:59:18.247Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 9: Explainable AI and Heatmap Visualization\n",
    "\n",
    "# 1. Function to Compute Grad-CAM Heatmap\n",
    "def get_gradcam_heatmap(model, img_array, layer):\n",
    "    \"\"\"Generates Grad-CAM heatmap for 2D models.\"\"\"\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=[layer.output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.expand_dims(img_array, axis=0))\n",
    "        loss = predictions[:, 0]  \n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0)  \n",
    "    heatmap /= np.max(heatmap) \n",
    "    return heatmap\n",
    "\n",
    "# 2. Extracting the last conv layers from EfficientNet and ResNet\n",
    "effnet = model_2d.get_layer(\"efficientnetv2-b0\")\n",
    "resnet = model_2d.get_layer(\"resnet50\")\n",
    "\n",
    "effnet_last_conv = effnet.layers[-2]  \n",
    "resnet_last_conv = resnet.layers[-2]  \n",
    "\n",
    "# 3. Compute Heatmaps for 2D Model\n",
    "heatmap_2d_effnet = get_gradcam_heatmap(model_2d, test_image, layer=effnet_last_conv)\n",
    "heatmap_2d_resnet = get_gradcam_heatmap(model_2d, test_image, layer=resnet_last_conv)\n",
    "\n",
    "# Merge both heatmaps (ensemble Grad-CAM)\n",
    "heatmap_2d = (heatmap_2d_effnet + heatmap_2d_resnet) / 2\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 7015299,
     "sourceId": 11231111,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5822.46314,
   "end_time": "2025-04-01T01:37:33.847327",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-01T00:00:31.384187",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
